\hypertarget{classmoa_1_1classifiers_1_1functions_1_1_s_g_d}{}\doxysection{moa.\+classifiers.\+functions.\+S\+GD Class Reference}
\label{classmoa_1_1classifiers_1_1functions_1_1_s_g_d}\index{moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}}


Inheritance diagram for moa.\+classifiers.\+functions.\+S\+GD\+:
% FIG 0


Collaboration diagram for moa.\+classifiers.\+functions.\+S\+GD\+:
% FIG 1
\doxysubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
String \mbox{\hyperlink{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_ae775e9b4d7ee2cb4d3d9f0f340b79bb4}{get\+Purpose\+String}} ()
\item 
void \mbox{\hyperlink{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a1b7cf7a4d2480be9a7273583fe0450a4}{set\+Lambda}} (double lambda)
\item 
double \mbox{\hyperlink{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_ac4023013d8ce9c6ab32a6ca44c49a38f}{get\+Lambda}} ()
\item 
void \mbox{\hyperlink{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a28d035c119a35693605fb01510aecb15}{set\+Loss\+Function}} (int function)
\item 
int \mbox{\hyperlink{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_aea84eb309cdb57f2f973f47f7c772ff9}{get\+Loss\+Function}} ()
\item 
void \mbox{\hyperlink{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a67e315053b7189895227c2174bdb4376}{set\+Learning\+Rate}} (double lr)
\item 
double \mbox{\hyperlink{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a91e3c936dff00f01f009d3771dbe8458}{get\+Learning\+Rate}} ()
\item 
void \mbox{\hyperlink{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a768a736fdf459668881a01fbc1fed815}{reset}} ()
\item 
void \mbox{\hyperlink{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a0decfc253629d5cb0e8e7633d8ca1768}{reset\+Learning\+Impl}} ()
\item 
void \mbox{\hyperlink{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_ab783d42c0b72dbc47dee632ee899eb0c}{train\+On\+Instance\+Impl}} (\mbox{\hyperlink{interfacecom_1_1yahoo_1_1labs_1_1samoa_1_1instances_1_1_instance}{Instance}} instance)
\item 
double\mbox{[}$\,$\mbox{]} \mbox{\hyperlink{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a05007ceccb6cc18317e6169f604c4c94}{get\+Votes\+For\+Instance}} (\mbox{\hyperlink{interfacecom_1_1yahoo_1_1labs_1_1samoa_1_1instances_1_1_instance}{Instance}} inst)
\item 
void \mbox{\hyperlink{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_afc00b8dfad914bcf9fe235b5245ea62a}{get\+Model\+Description}} (String\+Builder result, int indent)
\item 
String \mbox{\hyperlink{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a76cb2cf12f53e290bd3dcd00ed35fc10}{to\+String}} ()
\item 
boolean \mbox{\hyperlink{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a794c648479f695e7e9c130a00d5c7d46}{is\+Randomizable}} ()
\end{DoxyCompactItemize}
\doxysubsection*{Public Attributes}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classcom_1_1github_1_1javacliparser_1_1_float_option}{Float\+Option}} {\bfseries lambda\+Regularization\+Option}
\item 
\mbox{\hyperlink{classcom_1_1github_1_1javacliparser_1_1_float_option}{Float\+Option}} {\bfseries learning\+Rate\+Option}
\item 
\mbox{\hyperlink{classcom_1_1github_1_1javacliparser_1_1_multi_choice_option}{Multi\+Choice\+Option}} {\bfseries loss\+Function\+Option}
\end{DoxyCompactItemize}
\doxysubsection*{Protected Member Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a4117d8d6302804fd43fbc3bf57b9313f}\label{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a4117d8d6302804fd43fbc3bf57b9313f}} 
double {\bfseries dloss} (double z)
\item 
\mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_affc4fd296bb6be6f3def85235d38fd77}\label{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_affc4fd296bb6be6f3def85235d38fd77}} 
String {\bfseries get\+Model\+Name} ()
\item 
\mbox{\hyperlink{classmoa_1_1core_1_1_measurement}{Measurement}}\mbox{[}$\,$\mbox{]} \mbox{\hyperlink{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a77cd5027c9ec2073e0aa69b805c2e288}{get\+Model\+Measurements\+Impl}} ()
\end{DoxyCompactItemize}
\doxysubsection*{Static Protected Member Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a989da08a53b9296d907b2566f2a21e4a}\label{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a989da08a53b9296d907b2566f2a21e4a}} 
static double {\bfseries dot\+Prod} (\mbox{\hyperlink{interfacecom_1_1yahoo_1_1labs_1_1samoa_1_1instances_1_1_instance}{Instance}} inst1, \mbox{\hyperlink{classmoa_1_1core_1_1_double_vector}{Double\+Vector}} weights, int class\+Index)
\end{DoxyCompactItemize}
\doxysubsection*{Protected Attributes}
\begin{DoxyCompactItemize}
\item 
double \mbox{\hyperlink{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_aef6ddb95baa3107020030c3a973b500e}{m\+\_\+lambda}} = 0.\+0001
\item 
double \mbox{\hyperlink{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_af6f5acdc2f37098999d982c35ffabab1}{m\+\_\+learning\+Rate}} = 0.\+01
\item 
\mbox{\hyperlink{classmoa_1_1core_1_1_double_vector}{Double\+Vector}} \mbox{\hyperlink{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a306dff3012512cd68a30a3b14bbe08a1}{m\+\_\+weights}}
\item 
\mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a81dd5fe06f9cee613b0d161cf16dc987}\label{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a81dd5fe06f9cee613b0d161cf16dc987}} 
double {\bfseries m\+\_\+bias}
\item 
double \mbox{\hyperlink{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a138645a934d50aaa08be5b64648c6ec4}{m\+\_\+t}}
\item 
double \mbox{\hyperlink{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a2c5fdf5a01ffffc4f9ef762e9732001a}{m\+\_\+num\+Instances}}
\item 
int \mbox{\hyperlink{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a4f88dd2d4414c934913ac1fe6c7432b9}{m\+\_\+loss}} = H\+I\+N\+GE
\end{DoxyCompactItemize}
\doxysubsection*{Static Protected Attributes}
\begin{DoxyCompactItemize}
\item 
\mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_ac740459988e126f4e6486ad348fa84b0}\label{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_ac740459988e126f4e6486ad348fa84b0}} 
static final int {\bfseries H\+I\+N\+GE} = 0
\item 
\mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a4da2f7d65f96ae26c924e864e7405aff}\label{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a4da2f7d65f96ae26c924e864e7405aff}} 
static final int {\bfseries L\+O\+G\+L\+O\+SS} = 1
\item 
\mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_acf83ae1150281da248ef619154618f6b}\label{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_acf83ae1150281da248ef619154618f6b}} 
static final int {\bfseries S\+Q\+U\+A\+R\+E\+D\+L\+O\+SS} = 2
\end{DoxyCompactItemize}
\doxysubsection*{Additional Inherited Members}


\doxysubsection{Detailed Description}
Implements stochastic gradient descent for learning various linear models (binary class S\+VM, binary class logistic regression and linear regression). 

\doxysubsection{Member Function Documentation}
\mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_ac4023013d8ce9c6ab32a6ca44c49a38f}\label{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_ac4023013d8ce9c6ab32a6ca44c49a38f}} 
\index{moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}!getLambda@{getLambda}}
\index{getLambda@{getLambda}!moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}}
\doxysubsubsection{\texorpdfstring{getLambda()}{getLambda()}}
{\footnotesize\ttfamily double moa.\+classifiers.\+functions.\+S\+G\+D.\+get\+Lambda (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})}

Get the current value of lambda

\begin{DoxyReturn}{Returns}
the current value of lambda 
\end{DoxyReturn}
\mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a91e3c936dff00f01f009d3771dbe8458}\label{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a91e3c936dff00f01f009d3771dbe8458}} 
\index{moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}!getLearningRate@{getLearningRate}}
\index{getLearningRate@{getLearningRate}!moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}}
\doxysubsubsection{\texorpdfstring{getLearningRate()}{getLearningRate()}}
{\footnotesize\ttfamily double moa.\+classifiers.\+functions.\+S\+G\+D.\+get\+Learning\+Rate (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})}

Get the learning rate.

\begin{DoxyReturn}{Returns}
the learning rate 
\end{DoxyReturn}
\mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_aea84eb309cdb57f2f973f47f7c772ff9}\label{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_aea84eb309cdb57f2f973f47f7c772ff9}} 
\index{moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}!getLossFunction@{getLossFunction}}
\index{getLossFunction@{getLossFunction}!moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}}
\doxysubsubsection{\texorpdfstring{getLossFunction()}{getLossFunction()}}
{\footnotesize\ttfamily int moa.\+classifiers.\+functions.\+S\+G\+D.\+get\+Loss\+Function (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})}

Get the current loss function.

\begin{DoxyReturn}{Returns}
the current loss function. 
\end{DoxyReturn}
\mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_afc00b8dfad914bcf9fe235b5245ea62a}\label{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_afc00b8dfad914bcf9fe235b5245ea62a}} 
\index{moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}!getModelDescription@{getModelDescription}}
\index{getModelDescription@{getModelDescription}!moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}}
\doxysubsubsection{\texorpdfstring{getModelDescription()}{getModelDescription()}}
{\footnotesize\ttfamily void moa.\+classifiers.\+functions.\+S\+G\+D.\+get\+Model\+Description (\begin{DoxyParamCaption}\item[{String\+Builder}]{out,  }\item[{int}]{indent }\end{DoxyParamCaption})}

Returns a string representation of the model.


\begin{DoxyParams}{Parameters}
{\em out} & the stringbuilder to add the description \\
\hline
{\em indent} & the number of characters to indent \\
\hline
\end{DoxyParams}


Reimplemented from \mbox{\hyperlink{classmoa_1_1classifiers_1_1_abstract_classifier_a30e5ff32bc8127dfb7436945776b7523}{moa.\+classifiers.\+Abstract\+Classifier}}.

\mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a77cd5027c9ec2073e0aa69b805c2e288}\label{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a77cd5027c9ec2073e0aa69b805c2e288}} 
\index{moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}!getModelMeasurementsImpl@{getModelMeasurementsImpl}}
\index{getModelMeasurementsImpl@{getModelMeasurementsImpl}!moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}}
\doxysubsubsection{\texorpdfstring{getModelMeasurementsImpl()}{getModelMeasurementsImpl()}}
{\footnotesize\ttfamily \mbox{\hyperlink{classmoa_1_1core_1_1_measurement}{Measurement}} \mbox{[}$\,$\mbox{]} moa.\+classifiers.\+functions.\+S\+G\+D.\+get\+Model\+Measurements\+Impl (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [protected]}}

Gets the current measurements of this classifier.~\newline
~\newline


The reason for ...Impl methods\+: ease programmer burden by not requiring them to remember calls to super in overridden methods. Note that this will produce compiler errors if not overridden.

\begin{DoxyReturn}{Returns}
an array of measurements to be used in evaluation tasks 
\end{DoxyReturn}


Reimplemented from \mbox{\hyperlink{classmoa_1_1classifiers_1_1_abstract_classifier_ac2bebede21c9d2d8cd11d95a7e20e529}{moa.\+classifiers.\+Abstract\+Classifier}}.

\mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_ae775e9b4d7ee2cb4d3d9f0f340b79bb4}\label{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_ae775e9b4d7ee2cb4d3d9f0f340b79bb4}} 
\index{moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}!getPurposeString@{getPurposeString}}
\index{getPurposeString@{getPurposeString}!moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}}
\doxysubsubsection{\texorpdfstring{getPurposeString()}{getPurposeString()}}
{\footnotesize\ttfamily String moa.\+classifiers.\+functions.\+S\+G\+D.\+get\+Purpose\+String (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})}

Options to handle Dictionary with option texts and objects 

Reimplemented from \mbox{\hyperlink{classmoa_1_1classifiers_1_1_abstract_classifier_a3fc6ae11234b88e51941a77ddb879d8b}{moa.\+classifiers.\+Abstract\+Classifier}}.



Reimplemented in \mbox{\hyperlink{classmoa_1_1classifiers_1_1functions_1_1_ada_grad_ac79e47e5aa25785c049f005337bee38b}{moa.\+classifiers.\+functions.\+Ada\+Grad}}.

\mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a05007ceccb6cc18317e6169f604c4c94}\label{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a05007ceccb6cc18317e6169f604c4c94}} 
\index{moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}!getVotesForInstance@{getVotesForInstance}}
\index{getVotesForInstance@{getVotesForInstance}!moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}}
\doxysubsubsection{\texorpdfstring{getVotesForInstance()}{getVotesForInstance()}}
{\footnotesize\ttfamily double \mbox{[}$\,$\mbox{]} moa.\+classifiers.\+functions.\+S\+G\+D.\+get\+Votes\+For\+Instance (\begin{DoxyParamCaption}\item[{\mbox{\hyperlink{interfacecom_1_1yahoo_1_1labs_1_1samoa_1_1instances_1_1_instance}{Instance}}}]{inst }\end{DoxyParamCaption})}

Calculates the class membership probabilities for the given test instance.


\begin{DoxyParams}{Parameters}
{\em instance} & the instance to be classified \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
predicted class probability distribution 
\end{DoxyReturn}


Reimplemented from \mbox{\hyperlink{classmoa_1_1classifiers_1_1_abstract_classifier_a0e3589c4fa6f088d82d64514afd9513c}{moa.\+classifiers.\+Abstract\+Classifier}}.

\mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a794c648479f695e7e9c130a00d5c7d46}\label{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a794c648479f695e7e9c130a00d5c7d46}} 
\index{moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}!isRandomizable@{isRandomizable}}
\index{isRandomizable@{isRandomizable}!moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}}
\doxysubsubsection{\texorpdfstring{isRandomizable()}{isRandomizable()}}
{\footnotesize\ttfamily boolean moa.\+classifiers.\+functions.\+S\+G\+D.\+is\+Randomizable (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})}

Gets whether this learner needs a random seed. Examples of methods that needs a random seed are bagging and boosting.

\begin{DoxyReturn}{Returns}
true if the learner needs a random seed. 
\end{DoxyReturn}


Implements \mbox{\hyperlink{interfacemoa_1_1learners_1_1_learner_a2f1ff9007b5eb5f53801f474b4d42a61}{moa.\+learners.\+Learner$<$ E extends Example $>$}}.

\mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a768a736fdf459668881a01fbc1fed815}\label{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a768a736fdf459668881a01fbc1fed815}} 
\index{moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}!reset@{reset}}
\index{reset@{reset}!moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}}
\doxysubsubsection{\texorpdfstring{reset()}{reset()}}
{\footnotesize\ttfamily void moa.\+classifiers.\+functions.\+S\+G\+D.\+reset (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})}

Reset the classifier. \mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a0decfc253629d5cb0e8e7633d8ca1768}\label{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a0decfc253629d5cb0e8e7633d8ca1768}} 
\index{moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}!resetLearningImpl@{resetLearningImpl}}
\index{resetLearningImpl@{resetLearningImpl}!moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}}
\doxysubsubsection{\texorpdfstring{resetLearningImpl()}{resetLearningImpl()}}
{\footnotesize\ttfamily void moa.\+classifiers.\+functions.\+S\+G\+D.\+reset\+Learning\+Impl (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})}

Resets this classifier. It must be similar to starting a new classifier from scratch. ~\newline
~\newline


The reason for ...Impl methods\+: ease programmer burden by not requiring them to remember calls to super in overridden methods. Note that this will produce compiler errors if not overridden. 

Reimplemented from \mbox{\hyperlink{classmoa_1_1classifiers_1_1_abstract_classifier_a099ffcf2417abb919d10d697c0648f29}{moa.\+classifiers.\+Abstract\+Classifier}}.



Reimplemented in \mbox{\hyperlink{classmoa_1_1classifiers_1_1functions_1_1_ada_grad_a58454c119c1bc8c1329f40093f9d74d7}{moa.\+classifiers.\+functions.\+Ada\+Grad}}.

\mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a1b7cf7a4d2480be9a7273583fe0450a4}\label{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a1b7cf7a4d2480be9a7273583fe0450a4}} 
\index{moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}!setLambda@{setLambda}}
\index{setLambda@{setLambda}!moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}}
\doxysubsubsection{\texorpdfstring{setLambda()}{setLambda()}}
{\footnotesize\ttfamily void moa.\+classifiers.\+functions.\+S\+G\+D.\+set\+Lambda (\begin{DoxyParamCaption}\item[{double}]{lambda }\end{DoxyParamCaption})}

Set the value of lambda to use


\begin{DoxyParams}{Parameters}
{\em lambda} & the value of lambda to use \\
\hline
\end{DoxyParams}
\mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a67e315053b7189895227c2174bdb4376}\label{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a67e315053b7189895227c2174bdb4376}} 
\index{moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}!setLearningRate@{setLearningRate}}
\index{setLearningRate@{setLearningRate}!moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}}
\doxysubsubsection{\texorpdfstring{setLearningRate()}{setLearningRate()}}
{\footnotesize\ttfamily void moa.\+classifiers.\+functions.\+S\+G\+D.\+set\+Learning\+Rate (\begin{DoxyParamCaption}\item[{double}]{lr }\end{DoxyParamCaption})}

Set the learning rate.


\begin{DoxyParams}{Parameters}
{\em lr} & the learning rate to use. \\
\hline
\end{DoxyParams}
\mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a28d035c119a35693605fb01510aecb15}\label{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a28d035c119a35693605fb01510aecb15}} 
\index{moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}!setLossFunction@{setLossFunction}}
\index{setLossFunction@{setLossFunction}!moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}}
\doxysubsubsection{\texorpdfstring{setLossFunction()}{setLossFunction()}}
{\footnotesize\ttfamily void moa.\+classifiers.\+functions.\+S\+G\+D.\+set\+Loss\+Function (\begin{DoxyParamCaption}\item[{int}]{function }\end{DoxyParamCaption})}

Set the loss function to use.


\begin{DoxyParams}{Parameters}
{\em function} & the loss function to use. \\
\hline
\end{DoxyParams}
\mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a76cb2cf12f53e290bd3dcd00ed35fc10}\label{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a76cb2cf12f53e290bd3dcd00ed35fc10}} 
\index{moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}!toString@{toString}}
\index{toString@{toString}!moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}}
\doxysubsubsection{\texorpdfstring{toString()}{toString()}}
{\footnotesize\ttfamily String moa.\+classifiers.\+functions.\+S\+G\+D.\+to\+String (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})}

Prints out the classifier.

\begin{DoxyReturn}{Returns}
a description of the classifier as a string 
\end{DoxyReturn}


Reimplemented from \mbox{\hyperlink{classmoa_1_1_abstract_m_o_a_object_ac686fd3b07c734cf21f1894376fe402d}{moa.\+Abstract\+M\+O\+A\+Object}}.

\mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_ab783d42c0b72dbc47dee632ee899eb0c}\label{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_ab783d42c0b72dbc47dee632ee899eb0c}} 
\index{moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}!trainOnInstanceImpl@{trainOnInstanceImpl}}
\index{trainOnInstanceImpl@{trainOnInstanceImpl}!moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}}
\doxysubsubsection{\texorpdfstring{trainOnInstanceImpl()}{trainOnInstanceImpl()}}
{\footnotesize\ttfamily void moa.\+classifiers.\+functions.\+S\+G\+D.\+train\+On\+Instance\+Impl (\begin{DoxyParamCaption}\item[{\mbox{\hyperlink{interfacecom_1_1yahoo_1_1labs_1_1samoa_1_1instances_1_1_instance}{Instance}}}]{instance }\end{DoxyParamCaption})}

Trains the classifier with the given instance.


\begin{DoxyParams}{Parameters}
{\em instance} & the new training instance to include in the model \\
\hline
\end{DoxyParams}


Reimplemented from \mbox{\hyperlink{classmoa_1_1classifiers_1_1_abstract_classifier_aceb24d2ddeab386f2ecead6e3c0d3543}{moa.\+classifiers.\+Abstract\+Classifier}}.



Reimplemented in \mbox{\hyperlink{classmoa_1_1classifiers_1_1functions_1_1_ada_grad_a380eaef595dbc023cfa2bdac405cba7a}{moa.\+classifiers.\+functions.\+Ada\+Grad}}.



\doxysubsection{Member Data Documentation}
\mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a1ba4a4de79dcd91845e7e428568dd494}\label{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a1ba4a4de79dcd91845e7e428568dd494}} 
\index{moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}!lambdaRegularizationOption@{lambdaRegularizationOption}}
\index{lambdaRegularizationOption@{lambdaRegularizationOption}!moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}}
\doxysubsubsection{\texorpdfstring{lambdaRegularizationOption}{lambdaRegularizationOption}}
{\footnotesize\ttfamily \mbox{\hyperlink{classcom_1_1github_1_1javacliparser_1_1_float_option}{Float\+Option}} moa.\+classifiers.\+functions.\+S\+G\+D.\+lambda\+Regularization\+Option}

{\bfseries Initial value\+:}
\begin{DoxyCode}{0}
\DoxyCodeLine{= \textcolor{keyword}{new} FloatOption(\textcolor{stringliteral}{"lambdaRegularization"},}
\DoxyCodeLine{            \textcolor{charliteral}{'l'}, \textcolor{stringliteral}{"Lambda regularization parameter ."},}
\DoxyCodeLine{            0.0001, 0.00, Integer.MAX\_VALUE)}

\end{DoxyCode}
\mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_addf745aa14535c29fb3634c8ed3f9201}\label{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_addf745aa14535c29fb3634c8ed3f9201}} 
\index{moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}!learningRateOption@{learningRateOption}}
\index{learningRateOption@{learningRateOption}!moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}}
\doxysubsubsection{\texorpdfstring{learningRateOption}{learningRateOption}}
{\footnotesize\ttfamily \mbox{\hyperlink{classcom_1_1github_1_1javacliparser_1_1_float_option}{Float\+Option}} moa.\+classifiers.\+functions.\+S\+G\+D.\+learning\+Rate\+Option}

{\bfseries Initial value\+:}
\begin{DoxyCode}{0}
\DoxyCodeLine{= \textcolor{keyword}{new} FloatOption(\textcolor{stringliteral}{"learningRate"},}
\DoxyCodeLine{            \textcolor{charliteral}{'r'}, \textcolor{stringliteral}{"Learning rate parameter."},}
\DoxyCodeLine{            0.0001, 0.00, Integer.MAX\_VALUE)}

\end{DoxyCode}
\mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a2acc92230fc27547f858458a130eaafc}\label{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a2acc92230fc27547f858458a130eaafc}} 
\index{moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}!lossFunctionOption@{lossFunctionOption}}
\index{lossFunctionOption@{lossFunctionOption}!moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}}
\doxysubsubsection{\texorpdfstring{lossFunctionOption}{lossFunctionOption}}
{\footnotesize\ttfamily \mbox{\hyperlink{classcom_1_1github_1_1javacliparser_1_1_multi_choice_option}{Multi\+Choice\+Option}} moa.\+classifiers.\+functions.\+S\+G\+D.\+loss\+Function\+Option}

{\bfseries Initial value\+:}
\begin{DoxyCode}{0}
\DoxyCodeLine{= \textcolor{keyword}{new} MultiChoiceOption(}
\DoxyCodeLine{            \textcolor{stringliteral}{"lossFunction"}, \textcolor{charliteral}{'o'}, \textcolor{stringliteral}{"The loss function to use."}, \textcolor{keyword}{new} String[]\{}
\DoxyCodeLine{                \textcolor{stringliteral}{"HINGE"}, \textcolor{stringliteral}{"LOGLOSS"}, \textcolor{stringliteral}{"SQUAREDLOSS"}\}, \textcolor{keyword}{new} String[]\{}
\DoxyCodeLine{                \textcolor{stringliteral}{"Hinge loss (SVM)"},}
\DoxyCodeLine{                \textcolor{stringliteral}{"Log loss (logistic regression)"},}
\DoxyCodeLine{                \textcolor{stringliteral}{"Squared loss (regression)"}\}, 0)}

\end{DoxyCode}
\mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_aef6ddb95baa3107020030c3a973b500e}\label{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_aef6ddb95baa3107020030c3a973b500e}} 
\index{moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}!m\_lambda@{m\_lambda}}
\index{m\_lambda@{m\_lambda}!moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}}
\doxysubsubsection{\texorpdfstring{m\_lambda}{m\_lambda}}
{\footnotesize\ttfamily double moa.\+classifiers.\+functions.\+S\+G\+D.\+m\+\_\+lambda = 0.\+0001\hspace{0.3cm}{\ttfamily [protected]}}

The regularization parameter \mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_af6f5acdc2f37098999d982c35ffabab1}\label{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_af6f5acdc2f37098999d982c35ffabab1}} 
\index{moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}!m\_learningRate@{m\_learningRate}}
\index{m\_learningRate@{m\_learningRate}!moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}}
\doxysubsubsection{\texorpdfstring{m\_learningRate}{m\_learningRate}}
{\footnotesize\ttfamily double moa.\+classifiers.\+functions.\+S\+G\+D.\+m\+\_\+learning\+Rate = 0.\+01\hspace{0.3cm}{\ttfamily [protected]}}

The learning rate \mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a4f88dd2d4414c934913ac1fe6c7432b9}\label{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a4f88dd2d4414c934913ac1fe6c7432b9}} 
\index{moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}!m\_loss@{m\_loss}}
\index{m\_loss@{m\_loss}!moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}}
\doxysubsubsection{\texorpdfstring{m\_loss}{m\_loss}}
{\footnotesize\ttfamily int moa.\+classifiers.\+functions.\+S\+G\+D.\+m\+\_\+loss = H\+I\+N\+GE\hspace{0.3cm}{\ttfamily [protected]}}

The current loss function to minimize \mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a2c5fdf5a01ffffc4f9ef762e9732001a}\label{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a2c5fdf5a01ffffc4f9ef762e9732001a}} 
\index{moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}!m\_numInstances@{m\_numInstances}}
\index{m\_numInstances@{m\_numInstances}!moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}}
\doxysubsubsection{\texorpdfstring{m\_numInstances}{m\_numInstances}}
{\footnotesize\ttfamily double moa.\+classifiers.\+functions.\+S\+G\+D.\+m\+\_\+num\+Instances\hspace{0.3cm}{\ttfamily [protected]}}

The number of training instances \mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a138645a934d50aaa08be5b64648c6ec4}\label{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a138645a934d50aaa08be5b64648c6ec4}} 
\index{moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}!m\_t@{m\_t}}
\index{m\_t@{m\_t}!moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}}
\doxysubsubsection{\texorpdfstring{m\_t}{m\_t}}
{\footnotesize\ttfamily double moa.\+classifiers.\+functions.\+S\+G\+D.\+m\+\_\+t\hspace{0.3cm}{\ttfamily [protected]}}

Holds the current iteration number \mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a306dff3012512cd68a30a3b14bbe08a1}\label{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a306dff3012512cd68a30a3b14bbe08a1}} 
\index{moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}!m\_weights@{m\_weights}}
\index{m\_weights@{m\_weights}!moa.classifiers.functions.SGD@{moa.classifiers.functions.SGD}}
\doxysubsubsection{\texorpdfstring{m\_weights}{m\_weights}}
{\footnotesize\ttfamily \mbox{\hyperlink{classmoa_1_1core_1_1_double_vector}{Double\+Vector}} moa.\+classifiers.\+functions.\+S\+G\+D.\+m\+\_\+weights\hspace{0.3cm}{\ttfamily [protected]}}

Stores the weights (+ bias in the last element) 

The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
C\+:/\+Users/\+Edbard/eclipse-\/java-\/workspace/\+Proyecto\+M\+O\+A/moa/src/main/java/moa/classifiers/functions/S\+G\+D.\+java\end{DoxyCompactItemize}
