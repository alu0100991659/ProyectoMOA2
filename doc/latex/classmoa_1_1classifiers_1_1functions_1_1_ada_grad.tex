\hypertarget{classmoa_1_1classifiers_1_1functions_1_1_ada_grad}{}\doxysection{moa.\+classifiers.\+functions.\+Ada\+Grad Class Reference}
\label{classmoa_1_1classifiers_1_1functions_1_1_ada_grad}\index{moa.classifiers.functions.AdaGrad@{moa.classifiers.functions.AdaGrad}}


Inheritance diagram for moa.\+classifiers.\+functions.\+Ada\+Grad\+:
% FIG 0


Collaboration diagram for moa.\+classifiers.\+functions.\+Ada\+Grad\+:
% FIG 1
\doxysubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
String \mbox{\hyperlink{classmoa_1_1classifiers_1_1functions_1_1_ada_grad_ac79e47e5aa25785c049f005337bee38b}{get\+Purpose\+String}} ()
\item 
void \mbox{\hyperlink{classmoa_1_1classifiers_1_1functions_1_1_ada_grad_a20a0ad68695b7bdac7c0757248a6d801}{set\+Epsilon}} (double eps)
\item 
double \mbox{\hyperlink{classmoa_1_1classifiers_1_1functions_1_1_ada_grad_a66d0dd62a52989ba083c73c72a768082}{get\+Epsilon}} ()
\item 
void \mbox{\hyperlink{classmoa_1_1classifiers_1_1functions_1_1_ada_grad_a58454c119c1bc8c1329f40093f9d74d7}{reset\+Learning\+Impl}} ()
\item 
void \mbox{\hyperlink{classmoa_1_1classifiers_1_1functions_1_1_ada_grad_a380eaef595dbc023cfa2bdac405cba7a}{train\+On\+Instance\+Impl}} (\mbox{\hyperlink{interfacecom_1_1yahoo_1_1labs_1_1samoa_1_1instances_1_1_instance}{Instance}} instance)
\end{DoxyCompactItemize}
\doxysubsection*{Public Attributes}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classcom_1_1github_1_1javacliparser_1_1_float_option}{Float\+Option}} {\bfseries epsilon\+Option}
\end{DoxyCompactItemize}
\doxysubsection*{Protected Member Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_ada_grad_a8d7915ef919e68acb7e55b769de59905}\label{classmoa_1_1classifiers_1_1functions_1_1_ada_grad_a8d7915ef919e68acb7e55b769de59905}} 
String {\bfseries get\+Model\+Name} ()
\end{DoxyCompactItemize}
\doxysubsection*{Protected Attributes}
\begin{DoxyCompactItemize}
\item 
double \mbox{\hyperlink{classmoa_1_1classifiers_1_1functions_1_1_ada_grad_a8bcb3c4d51b4d1ee201a36187412c217}{m\+\_\+epsilon}} = 1e-\/8
\item 
\mbox{\hyperlink{classmoa_1_1core_1_1_double_vector}{Double\+Vector}} \mbox{\hyperlink{classmoa_1_1classifiers_1_1functions_1_1_ada_grad_a2903725f81647d117501c6dc2bd0e253}{m\+\_\+velocity}}
\item 
\mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_ada_grad_ace34f52bdc97064abe9571f5d7925f0e}\label{classmoa_1_1classifiers_1_1functions_1_1_ada_grad_ace34f52bdc97064abe9571f5d7925f0e}} 
double {\bfseries m\+\_\+bias\+Velocity}
\end{DoxyCompactItemize}
\doxysubsection*{Additional Inherited Members}


\doxysubsection{Detailed Description}
Implements the \mbox{\hyperlink{classmoa_1_1classifiers_1_1functions_1_1_ada_grad}{Ada\+Grad}} oneline optimiser for learning various linear models (binary class S\+VM, binary class logistic regression and linear regression). For more information, see~\newline
 ~\newline
 Duchi, J., Hazan, E., \& Singer, Y. (2011). Adaptive subgradient methods for online learning and stochastic optimization. Journal of Machine Learning Research, 12 (Jul), 2121-\/2159. 


\begin{DoxyItemize}
\item Bib\+TeX\+: 
\begin{DoxyPre}
   \&\#64;inproceedings\{duchi2011,
      author = \{Duchi, John and Hazan, Elad and Singer, Yoram\},
      booktitle = \{Journal of Machine Learning Research\},
      pages = \{2121-\/-\/2159\},
      volume=\{12\},
      number=\{Jul\},
      title = \{Adaptive subgradient methods for online learning and stochastic optimization\},
      year = \{2011\}
   \}
   \end{DoxyPre}
 
\end{DoxyItemize}

\doxysubsection{Member Function Documentation}
\mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_ada_grad_a66d0dd62a52989ba083c73c72a768082}\label{classmoa_1_1classifiers_1_1functions_1_1_ada_grad_a66d0dd62a52989ba083c73c72a768082}} 
\index{moa.classifiers.functions.AdaGrad@{moa.classifiers.functions.AdaGrad}!getEpsilon@{getEpsilon}}
\index{getEpsilon@{getEpsilon}!moa.classifiers.functions.AdaGrad@{moa.classifiers.functions.AdaGrad}}
\doxysubsubsection{\texorpdfstring{getEpsilon()}{getEpsilon()}}
{\footnotesize\ttfamily double moa.\+classifiers.\+functions.\+Ada\+Grad.\+get\+Epsilon (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})}

Get the epsilon value.

\begin{DoxyReturn}{Returns}
the epsilon value 
\end{DoxyReturn}
\mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_ada_grad_ac79e47e5aa25785c049f005337bee38b}\label{classmoa_1_1classifiers_1_1functions_1_1_ada_grad_ac79e47e5aa25785c049f005337bee38b}} 
\index{moa.classifiers.functions.AdaGrad@{moa.classifiers.functions.AdaGrad}!getPurposeString@{getPurposeString}}
\index{getPurposeString@{getPurposeString}!moa.classifiers.functions.AdaGrad@{moa.classifiers.functions.AdaGrad}}
\doxysubsubsection{\texorpdfstring{getPurposeString()}{getPurposeString()}}
{\footnotesize\ttfamily String moa.\+classifiers.\+functions.\+Ada\+Grad.\+get\+Purpose\+String (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})}

Options to handle Dictionary with option texts and objects 

Reimplemented from \mbox{\hyperlink{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_ae775e9b4d7ee2cb4d3d9f0f340b79bb4}{moa.\+classifiers.\+functions.\+S\+GD}}.

\mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_ada_grad_a58454c119c1bc8c1329f40093f9d74d7}\label{classmoa_1_1classifiers_1_1functions_1_1_ada_grad_a58454c119c1bc8c1329f40093f9d74d7}} 
\index{moa.classifiers.functions.AdaGrad@{moa.classifiers.functions.AdaGrad}!resetLearningImpl@{resetLearningImpl}}
\index{resetLearningImpl@{resetLearningImpl}!moa.classifiers.functions.AdaGrad@{moa.classifiers.functions.AdaGrad}}
\doxysubsubsection{\texorpdfstring{resetLearningImpl()}{resetLearningImpl()}}
{\footnotesize\ttfamily void moa.\+classifiers.\+functions.\+Ada\+Grad.\+reset\+Learning\+Impl (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})}

Resets this classifier. It must be similar to starting a new classifier from scratch. ~\newline
~\newline


The reason for ...Impl methods\+: ease programmer burden by not requiring them to remember calls to super in overridden methods. Note that this will produce compiler errors if not overridden. 

Reimplemented from \mbox{\hyperlink{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_a0decfc253629d5cb0e8e7633d8ca1768}{moa.\+classifiers.\+functions.\+S\+GD}}.

\mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_ada_grad_a20a0ad68695b7bdac7c0757248a6d801}\label{classmoa_1_1classifiers_1_1functions_1_1_ada_grad_a20a0ad68695b7bdac7c0757248a6d801}} 
\index{moa.classifiers.functions.AdaGrad@{moa.classifiers.functions.AdaGrad}!setEpsilon@{setEpsilon}}
\index{setEpsilon@{setEpsilon}!moa.classifiers.functions.AdaGrad@{moa.classifiers.functions.AdaGrad}}
\doxysubsubsection{\texorpdfstring{setEpsilon()}{setEpsilon()}}
{\footnotesize\ttfamily void moa.\+classifiers.\+functions.\+Ada\+Grad.\+set\+Epsilon (\begin{DoxyParamCaption}\item[{double}]{eps }\end{DoxyParamCaption})}

Set the epsilon value.


\begin{DoxyParams}{Parameters}
{\em eps} & the epsilon value to use. \\
\hline
\end{DoxyParams}
\mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_ada_grad_a380eaef595dbc023cfa2bdac405cba7a}\label{classmoa_1_1classifiers_1_1functions_1_1_ada_grad_a380eaef595dbc023cfa2bdac405cba7a}} 
\index{moa.classifiers.functions.AdaGrad@{moa.classifiers.functions.AdaGrad}!trainOnInstanceImpl@{trainOnInstanceImpl}}
\index{trainOnInstanceImpl@{trainOnInstanceImpl}!moa.classifiers.functions.AdaGrad@{moa.classifiers.functions.AdaGrad}}
\doxysubsubsection{\texorpdfstring{trainOnInstanceImpl()}{trainOnInstanceImpl()}}
{\footnotesize\ttfamily void moa.\+classifiers.\+functions.\+Ada\+Grad.\+train\+On\+Instance\+Impl (\begin{DoxyParamCaption}\item[{\mbox{\hyperlink{interfacecom_1_1yahoo_1_1labs_1_1samoa_1_1instances_1_1_instance}{Instance}}}]{instance }\end{DoxyParamCaption})}

Trains the classifier with the given instance.


\begin{DoxyParams}{Parameters}
{\em instance} & the new training instance to include in the model \\
\hline
\end{DoxyParams}


Reimplemented from \mbox{\hyperlink{classmoa_1_1classifiers_1_1functions_1_1_s_g_d_ab783d42c0b72dbc47dee632ee899eb0c}{moa.\+classifiers.\+functions.\+S\+GD}}.



\doxysubsection{Member Data Documentation}
\mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_ada_grad_ac697adc0620e0bfc7760879ad916378c}\label{classmoa_1_1classifiers_1_1functions_1_1_ada_grad_ac697adc0620e0bfc7760879ad916378c}} 
\index{moa.classifiers.functions.AdaGrad@{moa.classifiers.functions.AdaGrad}!epsilonOption@{epsilonOption}}
\index{epsilonOption@{epsilonOption}!moa.classifiers.functions.AdaGrad@{moa.classifiers.functions.AdaGrad}}
\doxysubsubsection{\texorpdfstring{epsilonOption}{epsilonOption}}
{\footnotesize\ttfamily \mbox{\hyperlink{classcom_1_1github_1_1javacliparser_1_1_float_option}{Float\+Option}} moa.\+classifiers.\+functions.\+Ada\+Grad.\+epsilon\+Option}

{\bfseries Initial value\+:}
\begin{DoxyCode}{0}
\DoxyCodeLine{= \textcolor{keyword}{new} FloatOption(\textcolor{stringliteral}{"epsilon"},}
\DoxyCodeLine{            \textcolor{charliteral}{'p'}, \textcolor{stringliteral}{"epsilon parameter."},}
\DoxyCodeLine{            1e-\/8)}

\end{DoxyCode}
\mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_ada_grad_a8bcb3c4d51b4d1ee201a36187412c217}\label{classmoa_1_1classifiers_1_1functions_1_1_ada_grad_a8bcb3c4d51b4d1ee201a36187412c217}} 
\index{moa.classifiers.functions.AdaGrad@{moa.classifiers.functions.AdaGrad}!m\_epsilon@{m\_epsilon}}
\index{m\_epsilon@{m\_epsilon}!moa.classifiers.functions.AdaGrad@{moa.classifiers.functions.AdaGrad}}
\doxysubsubsection{\texorpdfstring{m\_epsilon}{m\_epsilon}}
{\footnotesize\ttfamily double moa.\+classifiers.\+functions.\+Ada\+Grad.\+m\+\_\+epsilon = 1e-\/8\hspace{0.3cm}{\ttfamily [protected]}}

The epsilon value \mbox{\Hypertarget{classmoa_1_1classifiers_1_1functions_1_1_ada_grad_a2903725f81647d117501c6dc2bd0e253}\label{classmoa_1_1classifiers_1_1functions_1_1_ada_grad_a2903725f81647d117501c6dc2bd0e253}} 
\index{moa.classifiers.functions.AdaGrad@{moa.classifiers.functions.AdaGrad}!m\_velocity@{m\_velocity}}
\index{m\_velocity@{m\_velocity}!moa.classifiers.functions.AdaGrad@{moa.classifiers.functions.AdaGrad}}
\doxysubsubsection{\texorpdfstring{m\_velocity}{m\_velocity}}
{\footnotesize\ttfamily \mbox{\hyperlink{classmoa_1_1core_1_1_double_vector}{Double\+Vector}} moa.\+classifiers.\+functions.\+Ada\+Grad.\+m\+\_\+velocity\hspace{0.3cm}{\ttfamily [protected]}}

Stores the weights (+ bias in the last element) 

The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
C\+:/\+Users/\+Edbard/eclipse-\/java-\/workspace/\+Proyecto\+M\+O\+A/moa/src/main/java/moa/classifiers/functions/Ada\+Grad.\+java\end{DoxyCompactItemize}
